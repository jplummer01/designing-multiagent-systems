{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Your First Agent with AutoGen\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/victordibia/multiagent-systems-with-autogen/blob/main/ch02/ch2_1_first_agent.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "\n",
    "\n",
    "![Multi-agent](https://github.com/victordibia/multiagent-systems-with-autogen/blob/main/docs/images/agent.png?raw=true)\n",
    "\n",
    "Multi-agent AI apps (a setup where multiple agents powered by GenAI models collaborate autonomously) hold promise in addressing complex tasks. In this notebook, the goal is singular - help you build your Agent with AutoGen.\n",
    "\n",
    "\n",
    "\n",
    "## Installation\n",
    "\n",
    "We will be using the AutoGen high level API (AgentChat),  we will need to install the package accordingly. \n",
    "\n",
    "```bash\n",
    "pip install -U \"autogen-agentchat\" \"autogen-ext[openai,azure]\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U \"autogen-agentchat\" \"autogen-ext[openai,azure]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Generative AI Model for Your Agent\n",
    "\n",
    "Agents are powered by Generative AI models. We will be using an OpenAI model in this example.  You can create your own API key at [OpenAI][(https://platform.openai.com/signup](https://platform.openai.com/).\n",
    "\n",
    "OpenAI models require an API key. It is recommended that we set this as an environment variable.  \n",
    "\n",
    "- create a new file called `.env` in the folder for this notebook.\n",
    "- add the following line to the file, replacing `YOUR_OPENAI_API_KEY` with your actual OpenAI API key:\n",
    "\n",
    "```bash\n",
    "OPENAI_API_KEY=YOUR_OPENAI_API_KEY\n",
    "```\n",
    "- save the file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Basic Agent  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "What is the weather in New York?\n",
      "---------- TextMessage (weather_agent) ----------\n",
      "I'm unable to provide real-time weather updates or current data. For the most accurate and current weather information in New York, I recommend checking a reliable weather website or app, such as the National Weather Service, Weather.com, or a similar service.\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o\",\n",
    "    # api_key=\"YOUR_API_KEY\", add if not using .env\n",
    ")\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"weather_agent\",\n",
    "    model_client=model_client, \n",
    "    system_message=\"You are a helpful assistant.\",  \n",
    ")\n",
    "\n",
    "await Console(agent.run_stream(task=\"What is the weather in New York?\")) \n",
    "await model_client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giving Your Agent Access to A Tool \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "What is the weather in New York?\n",
      "---------- ToolCallRequestEvent (weather_agent) ----------\n",
      "[FunctionCall(id='call_WG6i3LtD5VlOQWgvVyedpt3A', arguments='{\"city\":\"New York\"}', name='get_weather')]\n",
      "---------- ToolCallExecutionEvent (weather_agent) ----------\n",
      "[FunctionExecutionResult(content='The weather in New York is 73 degrees and Sunny.', name='get_weather', call_id='call_WG6i3LtD5VlOQWgvVyedpt3A', is_error=False)]\n",
      "---------- ModelClientStreamingChunkEvent (weather_agent) ----------\n",
      "The weather in New York is currently 73 degrees and sunny.\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "# Define a model client. You can use other model client that implements\n",
    "# the `ChatCompletionClient` interface.\n",
    "model_client = OpenAIChatCompletionClient(\n",
    "    model=\"gpt-4o\",\n",
    "    # api_key=\"YOUR_API_KEY\",\n",
    ")\n",
    "\n",
    "\n",
    "# Define a simple function tool that the agent can use.\n",
    "# For this example, we use a fake weather tool for demonstration purposes.\n",
    "async def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the weather for a given city.\"\"\"\n",
    "    return f\"The weather in {city} is 73 degrees and Sunny.\"\n",
    "\n",
    "\n",
    "# Define an AssistantAgent with the model, tool, system message, and reflection enabled.\n",
    "# The system message instructs the agent via natural language.\n",
    "agent = AssistantAgent(\n",
    "    name=\"weather_agent\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_weather],\n",
    "    system_message=\"You are a helpful assistant.\",\n",
    "    reflect_on_tool_use=True,\n",
    "    model_client_stream=True,  # Enable streaming tokens from the model client.\n",
    ")\n",
    "\n",
    "\n",
    "# Run the agent and stream the messages to the console.\n",
    "async def main() -> None:\n",
    "    await Console(agent.run_stream(task=\"What is the weather in New York?\"))\n",
    "    # Close the connection to the model client.\n",
    "    await model_client.close()\n",
    "\n",
    "\n",
    "# NOTE: if running this inside a Python script you'll need to use asyncio.run(main()).\n",
    "await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agnext",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
